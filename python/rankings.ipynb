{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series Module\n",
    "\n",
    "Copyright 2024 Michael George (AKA Logiqx).\n",
    "\n",
    "This file is part of [sse-results](https://github.com/Logiqx/sse-results) and is distributed under the terms of the GNU General Public License.\n",
    "\n",
    "sse-results is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.\n",
    "\n",
    "sse-results is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License along with sse-results. If not, see <https://www.gnu.org/licenses/>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation\n",
    "\n",
    "Basic approach to determine the project directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import json\n",
    "import csv\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "#from common import Printable, projdir\n",
    "#from event import Event\n",
    "#from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Printable:\n",
    "    def __init__(self, verbosity=1):\n",
    "        self.verbosity = verbosity\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.__class__) + \": \" + str(self.__dict__)\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.__class__) + \": \" + str(self.__dict__)\n",
    "    \n",
    "    def logInfo(self, msg):\n",
    "        if self.verbosity >= 2:\n",
    "            print('INFO:', msg)\n",
    "\n",
    "    def logWarning(self, msg):\n",
    "        if self.verbosity >= 1:\n",
    "            print('WARNING:', msg)\n",
    "\n",
    "    def logError(self, msg):\n",
    "        print('ERROR:', msg)\n",
    "        \n",
    "projdir = os.path.realpath(os.path.join(sys.path[0], '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVENTS_DIR = 'events'\n",
    "CONFIG_DIR = 'config'\n",
    "SAILWAVE_DIR = 'sailwave'\n",
    "DOCS_DIR = 'docs'\n",
    "\n",
    "APP_CONFIG = 'app.json'\n",
    "EVENT_CONFIG = 'event.json'\n",
    "\n",
    "COUNTRIES_CSV = 'countries.csv'\n",
    "ENTRANTS_CSV = 'entrants.csv'\n",
    "\n",
    "DEFAULT_COUNTRY = 'United Kingdom'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Django\n",
    "\n",
    "Copy / paste of slugify method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slugify(value):\n",
    "    \"\"\"\n",
    "    Taken from https://github.com/django/django/blob/master/django/utils/text.py\n",
    "    Convert to ASCII if 'allow_unicode' is False. Convert spaces or repeated\n",
    "    dashes to single dashes. Remove characters that aren't alphanumerics,\n",
    "    underscores, or hyphens. Convert to lowercase. Also strip leading and\n",
    "    trailing whitespace, dashes, and underscores.\n",
    "    \"\"\"\n",
    "    value = str(value)\n",
    "    value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')\n",
    "    value = re.sub(r'[^\\w\\s-]', '', value.lower())\n",
    "    return re.sub(r'[-\\s]+', '-', value).strip('-_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Years\n",
    "\n",
    "Process all available years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRiderId(row):\n",
    "    '''Get unique rider ID - suitable for Sailwave and native tables'''\n",
    "    \n",
    "    riderDetails = []\n",
    "    for riderDetail in ['name', 'sail-no', 'tally']:\n",
    "        if riderDetail in row:\n",
    "            riderDetails.append(row[riderDetail])\n",
    "\n",
    "    riderId = slugify('-'.join(riderDetails))\n",
    "    \n",
    "    return riderId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Event():\n",
    "    def __init__(self, path, appConfig, countries, verbosity=1):\n",
    "        \n",
    "        #super().__init__(verbosity=verbosity)\n",
    "\n",
    "        self.path = path\n",
    "        self.year = int(os.path.basename(path))\n",
    "\n",
    "        self.appConfig = appConfig\n",
    "        self.countries = countries\n",
    "\n",
    "        self.entrantFlags = {}\n",
    "        self.craftTypes = {}\n",
    "        \n",
    "        self.motions = {}\n",
    "        self.sessions = {}\n",
    "        \n",
    "        self.initialised = False\n",
    "\n",
    "\n",
    "    def loadConfig(self):\n",
    "        '''Read app config from JSON'''\n",
    "\n",
    "        filename = os.path.join(self.path, CONFIG_DIR, EVENT_CONFIG)\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            jsonTxt = f.read()\n",
    "            try:\n",
    "                self.eventConfig = json.loads(jsonTxt)\n",
    "            except:\n",
    "                self.logError('Could not parse {}'.format(filename))\n",
    "                raise\n",
    "\n",
    "    \n",
    "    def loadEntrantFlags(self):\n",
    "        '''Read entrant flags from CSV'''\n",
    "\n",
    "        filename = os.path.join(self.path, CONFIG_DIR, ENTRANTS_CSV)\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            csvReader = csv.DictReader(f)\n",
    "            for values in csvReader:\n",
    "                riderDetails = []\n",
    "                for riderDetail in ['First Name', 'Family Name', 'Sail No', 'Tally']:\n",
    "                    if riderDetail in values:\n",
    "                        riderDetails.append(values[riderDetail])\n",
    "                riderId = slugify('-'.join(riderDetails))\n",
    "\n",
    "                countryName = values['Country'].strip() or DEFAULT_COUNTRY\n",
    "                country = self.countries[countryName]\n",
    "                nation = '<td><i class=\"flag flag-{}\"></i>&nbsp;{}</td>'.format(country['Alpha-2 Code'], country['WSW Code'])\n",
    "\n",
    "                self.entrantFlags[riderId] = nation\n",
    "\n",
    "        return self.entrantFlags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNativeTitles(soup):\n",
    "    '''Get native titles from HTML soup'''\n",
    "    \n",
    "    titles = []\n",
    "    \n",
    "    summaryTitles = soup.find_all('h3')\n",
    "    for summaryTitle in summaryTitles:\n",
    "        titles.append(summaryTitle.text)\n",
    "\n",
    "    return titles\n",
    "\n",
    "    \n",
    "def getNativeColClasses(table):\n",
    "    '''Get native column classes from HTML soup'''\n",
    "    \n",
    "    colClasses = []\n",
    "\n",
    "    cols = table.find_all('col')\n",
    "    for col in cols:\n",
    "        colClasses.append(col['class'][0])\n",
    "\n",
    "    return colClasses\n",
    "\n",
    "    \n",
    "def getNativeRows(table, colClasses):\n",
    "    '''Get native table rows from HTML soup'''\n",
    "    \n",
    "    rows = {}\n",
    "\n",
    "    tbody = table.find('tbody')\n",
    "\n",
    "    trs = tbody.find_all('tr')\n",
    "    for tr in trs:\n",
    "        row = {}\n",
    "\n",
    "        tds = tr.find_all('td')\n",
    "        for i, td in enumerate(tds):\n",
    "            # Set some values to TBC, making it obvious if subsequent processing is unsuccessful\n",
    "            if colClasses[i] in ['rank', 'points', 'total']:\n",
    "                td.string = 'TBC'\n",
    "\n",
    "            # Nation needs to be kept intact (image and text)\n",
    "            if colClasses[i] == 'nation':\n",
    "                row[colClasses[i]] = str(td)\n",
    "            else:\n",
    "                row[colClasses[i]] = td.text\n",
    "\n",
    "        riderId = getRiderId(row)\n",
    "\n",
    "        rows[riderId] = row\n",
    "\n",
    "    return rows\n",
    "\n",
    "    \n",
    "def getNativeTables(results):\n",
    "    '''Get native tables from HTML soup'''\n",
    "    \n",
    "    soup = results['soup']\n",
    "\n",
    "    titles = getNativeTitles(soup)\n",
    "    tables = {}\n",
    "\n",
    "    summaryTables = soup.find_all('table')\n",
    "    for tableIdx, summaryTable in enumerate(summaryTables):\n",
    "        colClasses = getNativeColClasses(summaryTable)\n",
    "        tableRows = getNativeRows(summaryTable, colClasses)\n",
    "\n",
    "        title = titles[tableIdx]\n",
    "        tables[title] = tableRows\n",
    "\n",
    "    return tables\n",
    "\n",
    "    \n",
    "def loadNativeResults(event, seriesId):\n",
    "    '''Load native results into dictionary'''\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    results['filename'] = os.path.join(projdir, 'docs', EVENTS_DIR, str(event.year), seriesId.lower() + '.html')\n",
    "    with open(results['filename'], encoding='utf-8') as f:\n",
    "        html = f.read()\n",
    "        results['soup'] = BeautifulSoup(html, 'html.parser')\n",
    "        results['tables'] = getNativeTables(results)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSailwaveTitles(soup):\n",
    "    '''Get Sailwave titles from HTML soup'''\n",
    "    \n",
    "    titles = []\n",
    "    \n",
    "    summaryTitles = soup.find_all('h3', {'class': 'summarytitle'})\n",
    "    for summaryTitle in summaryTitles:\n",
    "        title = summaryTitle.text\n",
    "        if title.endswith(' Fleet'):\n",
    "            title = title.replace(' Fleet', '')\n",
    "        titles.append(title)\n",
    "\n",
    "    return titles\n",
    "\n",
    "    \n",
    "def getSailwaveColClasses(table):\n",
    "    '''Get Sailwave column classes from HTML soup'''\n",
    "    \n",
    "    colClasses = []\n",
    "\n",
    "    cols = table.find_all('col')\n",
    "    for col in cols:\n",
    "        colClass = col['class'][0]\n",
    "\n",
    "        if colClass == 'helmname':\n",
    "            colClass = 'name'\n",
    "        elif colClass == 'helmagegroup':\n",
    "            colClass = 'age'\n",
    "        elif colClass == 'sailno':\n",
    "            colClass = 'sail-no'\n",
    "\n",
    "        colClasses.append(colClass)\n",
    "\n",
    "    return colClasses\n",
    "\n",
    "    \n",
    "def getSailwaveRaceNames(table, colClasses):\n",
    "    '''Get Sailwave race names from HTML soup'''\n",
    "    \n",
    "    raceNames = []\n",
    "\n",
    "    ths = table.find_all('th')\n",
    "    for i, th in enumerate(ths):\n",
    "        if colClasses[i] == 'race':\n",
    "            raceNames.append(th.text)\n",
    "\n",
    "    return raceNames\n",
    "\n",
    "    \n",
    "def getSailwaveRows(table, colClasses):\n",
    "    '''Get Sailwave table rows from HTML soup'''\n",
    "    \n",
    "    rows = {}\n",
    "    \n",
    "    tbody = table.find('tbody')\n",
    "\n",
    "    trs = tbody.find_all('tr', {'class': 'summaryrow'})\n",
    "    for tr in trs:\n",
    "        row = {}\n",
    "        races = []\n",
    "\n",
    "        tds = tr.find_all('td')\n",
    "        for i, td in enumerate(tds):\n",
    "            if colClasses[i] == 'race':\n",
    "                races.append(td.text)\n",
    "            else:\n",
    "                row[colClasses[i]] = td.text\n",
    "\n",
    "        row['races'] = races\n",
    "        \n",
    "        # Points is a shortened form of the results\n",
    "        races = []\n",
    "        for race in row['races']:\n",
    "            codes = re.findall('[A-Z][A-Z][A-Z]', race)\n",
    "            if len(codes) > 0:\n",
    "                code = codes[0]\n",
    "                if '(' in race:\n",
    "                    code = '(' + code + ')'\n",
    "                races.append(code)\n",
    "            else:\n",
    "                races.append(race)\n",
    "        row['points'] = ' - '.join(races)\n",
    "\n",
    "        riderId = getRiderId(row)\n",
    "        rows[riderId] = row\n",
    "\n",
    "    return rows\n",
    "\n",
    "    \n",
    "def getSailwaveTables(results):\n",
    "    '''Get Sailwave tables from HTML soup'''\n",
    "    \n",
    "    soup = results['soup']\n",
    "\n",
    "    titles = getSailwaveTitles(soup)\n",
    "    tables = {}\n",
    "\n",
    "    summaryTables = soup.find_all('table', {'class': 'summarytable'})\n",
    "    for tableIdx, summaryTable in enumerate(summaryTables):\n",
    "        colClasses = getSailwaveColClasses(summaryTable)\n",
    "        raceNames = getSailwaveRaceNames(summaryTable, colClasses)\n",
    "        tableRows = getSailwaveRows(summaryTable, colClasses)\n",
    "\n",
    "        title = titles[tableIdx]\n",
    "        table = {'races': raceNames, 'rows': tableRows}\n",
    "        tables[title] = table\n",
    "\n",
    "    return tables\n",
    "\n",
    "    \n",
    "def loadSailwaveResults(event, seriesId):\n",
    "    '''Load Sailwave results into dictionary'''\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    results['filename'] = os.path.join(event.path, SAILWAVE_DIR, seriesId + '.html')   \n",
    "    with open(results['filename'], encoding='latin-1') as f:\n",
    "        html = f.read()\n",
    "        results['soup'] = BeautifulSoup(html, 'html.parser')\n",
    "        results['tables'] = getSailwaveTables(results)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copySpeeds(nativeResults, sailwaveResults, entrantFlags):\n",
    "    '''Copy best speeds from native results to sailwave results'''\n",
    "    \n",
    "    for title, sailwaveTable in sailwaveResults['tables'].items():\n",
    "        try:\n",
    "            nativeTable = nativeResults['tables'][title]\n",
    "\n",
    "        except KeyError:\n",
    "            logger = Printable()\n",
    "            logger.logError('Table \"{}\" not found in native results'.format(title))\n",
    "            raise\n",
    "\n",
    "        for rider, row in sailwaveTable['rows'].items():\n",
    "            try:\n",
    "                points = re.findall('[0-9]', row['points'])\n",
    "                if len(points) > 0:\n",
    "                    row['speed-kts'] = nativeTable[rider]['speed-kts']\n",
    "                else:\n",
    "                    row['speed-kts'] = '0.0'\n",
    "\n",
    "                # TODO - fix missing entries such as cedric-bordes-fra-91\n",
    "                if rider in nativeTable:\n",
    "                    row['nation'] = nativeTable[rider]['nation']\n",
    "                else:\n",
    "                    row['nation'] = entrantFlags[rider]\n",
    "\n",
    "            except KeyError:\n",
    "                logger = Printable()\n",
    "                logger.logError('Rider \"{}\" not found in native results'.format(rider))\n",
    "                raise\n",
    "            \n",
    "    return sailwaveResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortResults(results):\n",
    "    '''Prepare results for sorting according to rules for Prince of Speed 2023'''\n",
    "\n",
    "    # Use pre-compiled regex to extract points from race scores\n",
    "    pattern = re.compile('\\d+\\.\\d+')\n",
    "\n",
    "    for title, table in results['tables'].items():\n",
    "        rows = list(table['rows'].values())\n",
    "        for row in rows:\n",
    "            # Convert race scores which include codes such DNC to numerics\n",
    "            points = []\n",
    "            for race in row['races']:\n",
    "                points.append(float(pattern.findall(race)[0]))\n",
    "                \n",
    "            # A board’s series score is the total of its heat scores after discarding its worst scores\n",
    "            row['sort'] = [float(row['nett'])]\n",
    "            \n",
    "            # If there is a series score tie between two or more boards,\n",
    "            # it shall be broken in favour of the board(s) with the fastest run during the competition\n",
    "            #   N.B. multiplying by -1 avoids the need for reversed sorting for this one element\n",
    "            row['sort'] += [float(row['speed-kts']) * -1]\n",
    "            \n",
    "            # If a tie remains between two or more boards, each board’s heat scores,\n",
    "            # including excluded scores, shall be listed in order of best to worst,\n",
    "            # and at the first point(s) where there is a difference\n",
    "            # the tie shall be broken in favour of the board(s) with the best score(s).\n",
    "            # These scores shall be used even if some of them are excluded scores.\n",
    "            row['sort'] += sorted(points)\n",
    "            \n",
    "            # If a tie still remains between two or more boards,\n",
    "            # they shall be ranked in order of their scores in the last heat.\n",
    "            # Any remaining ties shall be broken by using the tied boards’ scores\n",
    "            # in the next-to-last heat and so on until all ties are broken.\n",
    "            # These scores shall be used even if some of them are excluded scores.\n",
    "            row['sort'] += reversed(points)\n",
    "\n",
    "            # Sort DNC / DNS competitors by name\n",
    "            row['sort'] += [row['name']]\n",
    "\n",
    "        # Python's sort algorithm is more than happy to use the pre-prepared \"sort\" lists\n",
    "        #   https://docs.python.org/3/howto/sorting.html\n",
    "        #   https://docs.python.org/3/reference/expressions.html#value-comparisons\n",
    "        rows.sort(key=itemgetter('sort'))\n",
    "        \n",
    "        table['sorted'] = rows\n",
    "\n",
    "        print(f'    {title}')\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexTables(soup):\n",
    "    '''Create index of the HTML tables based on the column classes'''\n",
    "    \n",
    "    tableIdx = []\n",
    "    titles = getNativeTitles(soup)\n",
    "\n",
    "    tables = soup.find_all('table')\n",
    "    for i, table in enumerate(tables):\n",
    "        columnIdx = []\n",
    "\n",
    "        cols = table.find_all('col')\n",
    "        for col in cols:\n",
    "            columnIdx.append(col['class'][0])\n",
    "\n",
    "        entry = {'title': titles[i], 'soup': table, 'cols': columnIdx}\n",
    "        tableIdx.append(entry)\n",
    "    \n",
    "    return tableIdx\n",
    "\n",
    "    \n",
    "def getDummyRow(soup, table):\n",
    "    '''Returns a dummy <tr> with the appropriate number of <td> items'''\n",
    "\n",
    "    # Determine number of columns from the header\n",
    "    numCols = len(table.find_all('th'))\n",
    "\n",
    "    # Create table row tag\n",
    "    tr = soup.new_tag('tr')\n",
    "\n",
    "    # Create table data tags\n",
    "    for i in range(numCols):\n",
    "        lf = soup.new_string('\\n')\n",
    "        tr.append(lf)\n",
    "        td = soup.new_tag('td')\n",
    "        tr.append(td)\n",
    "\n",
    "    lf = soup.new_string('\\n')\n",
    "    tr.append(lf)\n",
    "\n",
    "    return tr\n",
    "\n",
    "    \n",
    "def copyResults(sailwaveResults, nativeResults):\n",
    "    '''Copy sorted sailwave results to native results soup'''\n",
    "    \n",
    "    soup = nativeResults['soup']\n",
    "    tableIdx = indexTables(soup)\n",
    "\n",
    "    tables = soup.find_all('table')\n",
    "    for i, table in enumerate(tables):\n",
    "        title = tableIdx[i]['title']\n",
    "        cols = tableIdx[i]['cols']\n",
    "    \n",
    "        sailwaveTable = sailwaveResults['tables'][title]\n",
    "        sortedResults = sailwaveTable['sorted']\n",
    "        \n",
    "        # Ensure the number of rows is correct\n",
    "        trs = table.find_all('tr')[1:]\n",
    "\n",
    "        # Decompose rows that are not required\n",
    "        if len(trs) > len(sortedResults):\n",
    "            for tr in trs[len(sortedResults):]:\n",
    "                tr.decompose()\n",
    "\n",
    "        # Append rows that are missing\n",
    "        if len(trs) < len(sortedResults):\n",
    "            tbody = table.find('tbody')\n",
    "            numDummyRows = len(sortedResults) - len(trs)\n",
    "            for i in range(numDummyRows):\n",
    "                dummyRow = getDummyRow(soup, table)\n",
    "                tbody.append(dummyRow)\n",
    "                lf = soup.new_string('\\n')\n",
    "                tbody.append(lf)\n",
    "\n",
    "        # Replace all of the results\n",
    "        rank = 1\n",
    "        for j, tr in enumerate(table.find_all('tr')[1:]):\n",
    "            for k, td in enumerate(tr.find_all('td')):\n",
    "                if cols[k] == 'rank':\n",
    "                    td.string = str(rank)\n",
    "                    if float(sortedResults[j][cols[-1]]) > 0.0:\n",
    "                        rank += 1\n",
    "                elif cols[k] == 'nation':\n",
    "                    td.replace_with(BeautifulSoup(sortedResults[j][cols[k]], \"html.parser\"))\n",
    "                elif cols[k] == 'speed-kts' and float(sortedResults[j][cols[k]]) == 0.0:\n",
    "                    td.string = 'n/a'\n",
    "                else:\n",
    "                    td.string = sortedResults[j][cols[k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processEvent(event):\n",
    "    '''Process event series'''\n",
    "    \n",
    "    event.loadConfig()\n",
    "\n",
    "    if 'Series' in event.eventConfig:\n",
    "        print(f'Processing {event.path}...')\n",
    "\n",
    "        # Blend sailwave and native results\n",
    "        for seriesId, seriesInfo in event.eventConfig['Series'].items():\n",
    "            if 'Refresh' in seriesInfo and seriesInfo['Refresh']:\n",
    "                print(f'  {seriesInfo[\"Name\"]}')\n",
    "    \n",
    "                entrantFlags = event.loadEntrantFlags()\n",
    "\n",
    "                sailwaveResults = loadSailwaveResults(event, seriesId)\n",
    "                nativeResults = loadNativeResults(event, seriesId)\n",
    "    \n",
    "                copySpeeds(nativeResults, sailwaveResults, entrantFlags)\n",
    "                sortResults(sailwaveResults)\n",
    "                copyResults(sailwaveResults, nativeResults)\n",
    "\n",
    "                # Overwrite native results - indentation is lost and attribute orders change, but it's quick and easy!\n",
    "                with open(nativeResults['filename'], 'w', encoding='utf-8') as file:\n",
    "                    file.write(str(nativeResults['soup']))\n",
    "\n",
    "                print()\n",
    "\n",
    "\n",
    "def processEvents(countries):\n",
    "    '''Process all events from 1998 onwards'''\n",
    "\n",
    "    eventPaths = sorted(glob.glob(os.path.join(projdir, EVENTS_DIR, '[1-2][0-9][0-9][0-9]*')))\n",
    "    latestEvent = os.path.basename(eventPaths[-1])\n",
    "    for eventPath in eventPaths:\n",
    "        currentEvent = os.path.basename(eventPath)\n",
    "\n",
    "        if currentEvent == latestEvent and appConfig['Latest']['Refresh'] or \\\n",
    "                currentEvent != latestEvent and appConfig['History']['Refresh']:\n",
    "            if currentEvent == latestEvent:\n",
    "                verbosity = appConfig['Latest']['Verbosity']\n",
    "            else:\n",
    "                verbosity = appConfig['History']['Verbosity']\n",
    "\n",
    "            event = Event(eventPath, appConfig, countries, verbosity=verbosity)\n",
    "            processEvent(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCountries():\n",
    "    '''Read countries from CSV'''\n",
    "\n",
    "    countries = {}\n",
    "    \n",
    "    filename = os.path.join(projdir, CONFIG_DIR, COUNTRIES_CSV)\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        csvReader = csv.DictReader(f)\n",
    "        for values in csvReader:\n",
    "            countries[values['Name']] = values\n",
    "\n",
    "    return countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/jovyan/work/wsw-results/events/2008...\n",
      "Processing /home/jovyan/work/wsw-results/events/2009...\n",
      "Processing /home/jovyan/work/wsw-results/events/2010...\n",
      "Processing /home/jovyan/work/wsw-results/events/2011...\n",
      "Processing /home/jovyan/work/wsw-results/events/2012...\n",
      "Processing /home/jovyan/work/wsw-results/events/2013...\n",
      "Processing /home/jovyan/work/wsw-results/events/2014...\n",
      "Processing /home/jovyan/work/wsw-results/events/2015...\n",
      "Processing /home/jovyan/work/wsw-results/events/2016...\n",
      "Processing /home/jovyan/work/wsw-results/events/2017...\n",
      "Processing /home/jovyan/work/wsw-results/events/2018...\n",
      "Processing /home/jovyan/work/wsw-results/events/2019...\n",
      "Processing /home/jovyan/work/wsw-results/events/2020...\n",
      "Processing /home/jovyan/work/wsw-results/events/2021...\n",
      "Processing /home/jovyan/work/wsw-results/events/2022...\n",
      "Processing /home/jovyan/work/wsw-results/events/2023...\n",
      "Processing /home/jovyan/work/wsw-results/events/2024...\n",
      "  UKWA Speed Championship\n",
      "    Sailboard\n",
      "    Wingboard\n",
      "\n",
      "Reports completed in 0.06 seconds\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    pc1 = time.perf_counter()\n",
    "    \n",
    "    # Read main config\n",
    "    filename = os.path.join(projdir, CONFIG_DIR, APP_CONFIG)\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        jsonTxt = f.read()\n",
    "        try:\n",
    "            appConfig = json.loads(jsonTxt)\n",
    "        except:\n",
    "            logger = Printable()\n",
    "            logger.logError('Could not parse {}'.format(filename))\n",
    "            raise\n",
    "\n",
    "    countries = loadCountries()\n",
    "\n",
    "    # Process the required year(s)\n",
    "    processEvents(countries)\n",
    "    \n",
    "    pc2 = time.perf_counter()\n",
    "    print(\"Reports completed in %0.2f seconds\" % (pc2 - pc1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## All Done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
